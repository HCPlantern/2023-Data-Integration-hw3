{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:08:09.638705Z",
     "start_time": "2023-05-17T16:08:09.611038Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import dump, load\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, \\\n",
    "    cohen_kappa_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:08:09.684296Z",
     "start_time": "2023-05-17T16:08:09.621919Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义一些字符串信息\n",
    "# 该 worksheet 所有文件都保存在 ./v2_credit 下\n",
    "PATH = \"credit/\"\n",
    "PREFIX = PATH\n",
    "\n",
    "# 所有原始数据\n",
    "all_name = PREFIX + \"all.csv\"\n",
    "# 经过预处理的训练数据\n",
    "train_name = PREFIX + \"train.csv\"\n",
    "# 经过预处理的待预测数据\n",
    "predict_name = PREFIX + \"predict.csv\"\n",
    "\n",
    "describe_name = PREFIX + \"describe.csv\"\n",
    "missing_name = PREFIX + \"missing.csv\"\n",
    "zero_name = PREFIX + \"zero.csv\"\n",
    "trains_name = PREFIX + \"trans.csv\"\n",
    "std_name = PREFIX + \"std.csv\"\n",
    "corr_name = PREFIX + \"corr.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:04:53.710379Z",
     "start_time": "2023-05-17T16:04:53.462945Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 读取 csv 文件\n",
    "all_data = pd.read_csv(all_name)\n",
    "\n",
    "# 数据盘点\n",
    "all_data.describe().to_csv(describe_name)\n",
    "all_data.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:04:54.195807Z",
     "start_time": "2023-05-17T16:04:53.714401Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#2.1 缺失值和 0 值\n",
    "\n",
    "# 计算文件每一列的缺失值比例并保存至 missing.csv 文件\n",
    "all_data.isnull().mean().to_csv(missing_name)\n",
    "# 去除缺失值比例大于 0.7 的列，注意这里改变了 all_data 中的列\n",
    "all_data = all_data.loc[:, all_data.isnull().mean() < 0.7]\n",
    "\n",
    "#对于数值型变量，用中位数填充缺失值\n",
    "all_data.fillna(all_data.median(numeric_only=True), inplace=True)\n",
    "#对于类别型变量，用众数填充缺失值\n",
    "all_data.fillna(all_data.mode().iloc[0], inplace=True)\n",
    "\n",
    "# 计算文件每一列的 0 值比例并保存至 zero.csv 文件\n",
    "all_data.isin([0]).mean().to_csv(zero_name)\n",
    "# 去除全为 0 值的列\n",
    "all_data = all_data.loc[:, all_data.isin([0]).mean() != 1]\n",
    "\n",
    "#输出处理后的列名\n",
    "print(all_data.columns)\n",
    "#输出处理后的数据类型\n",
    "print(all_data.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:04:54.245292Z",
     "start_time": "2023-05-17T16:04:54.197900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义不同类型的列的列表\n",
    "\n",
    "# 所有的列，去除 uid 和 credit_level\n",
    "columns = all_data.columns.to_list()\n",
    "columns.remove('uid')\n",
    "columns.remove('credit_level')\n",
    "\n",
    "# columns 中的对象列\n",
    "catelist = [col for col in all_data.columns if col in columns and all_data[col].dtype == 'object']\n",
    "\n",
    "# columns 中的数值列\n",
    "numlist = [col for col in all_data.columns if col in columns and all_data[col].dtype == np.number]\n",
    "\n",
    "print(\"columns: len \", len(columns), columns)\n",
    "print(\"catelist: len\", len(catelist), catelist)\n",
    "print(\"numlist: len\", len(numlist), numlist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:04:54.938965Z",
     "start_time": "2023-05-17T16:04:54.212911Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2.3 数据转换\n",
    "# 将star_train数据中的类别变量进行 One-Hot 编码\n",
    "\n",
    "all_data = pd.get_dummies(all_data, columns=catelist)\n",
    "print(all_data.head())\n",
    "all_data.to_csv(trains_name, index=False)\n",
    "all_data.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:04:54.938965Z",
     "start_time": "2023-05-17T16:04:54.884734Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 独热编码之后，重新计算 columns\n",
    "# 所有的列，去除 uid 和 credit_level\n",
    "columns = all_data.columns.to_list()\n",
    "columns.remove('uid')\n",
    "columns.remove('credit_level')\n",
    "\n",
    "print(\"columns: len\", len(columns), columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:04:55.617807Z",
     "start_time": "2023-05-17T16:04:54.899755Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 划分训练数据和待预测数据\n",
    "train_data = all_data[all_data.credit_level != -1]\n",
    "predict_data = all_data[all_data.credit_level == -1]\n",
    "\n",
    "train_data.to_csv(train_name)\n",
    "predict_data.to_csv(predict_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:04:55.660857Z",
     "start_time": "2023-05-17T16:04:55.619464Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4 模型预测\n",
    "#\n",
    "# # 准备工作：将数据集分为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data[columns], train_data['credit_level'], test_size=0.4,\n",
    "                                                    random_state=42)\n",
    "# # 划分验证集和真正的测试集\n",
    "# X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:04:55.665093Z",
     "start_time": "2023-05-17T16:04:55.653851Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4.4 xgboost\n",
    "# encode y_train\n",
    "xgb_le = LabelEncoder()\n",
    "y_train = xgb_le.fit_transform(y_train)\n",
    "\n",
    "xgb_name = PREFIX + 'xgboost.joblib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:04:59.126307Z",
     "start_time": "2023-05-17T16:04:55.664090Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 创建一个xgboost分类器\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "dump(xgb, xgb_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:04:59.218827Z",
     "start_time": "2023-05-17T16:04:59.112309Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 读取训练模型\n",
    "model = load(xgb_name)\n",
    "# 预测\n",
    "y_pred = model.predict(X_test)\n",
    "# 如果使用 xgboost，需要将预测结果反编码\n",
    "y_pred = xgb_le.inverse_transform(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:04:59.570510Z",
     "start_time": "2023-05-17T16:04:59.225827Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 5 模型评估\n",
    "# 5.1 计算准确率\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('准确率为：', accuracy)\n",
    "# 5.2 混淆矩阵\n",
    "# 计算混淆矩阵并保存为图片\n",
    "# 假设 y_true, y_pred, class_names 已经定义\n",
    "save_path = PREFIX + 'confusion_matrix_xgb.png'\n",
    "labels = [35, 50, 60, 70, 85]\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=labels)\n",
    "disp.plot()\n",
    "disp.figure_.savefig(save_path)\n",
    "# 5.3 计算精确率和召回率\n",
    "precision = precision_score(y_test, y_pred, average='macro')  # 计算宏平均精确率\n",
    "recall = recall_score(y_test, y_pred, average='macro')  # 计算宏平均召回率\n",
    "\n",
    "print(\"精确率为: \", precision)\n",
    "print(\"召回率为: \", recall)\n",
    "# 5.4 计算F1分数\n",
    "f1 = f1_score(y_test, y_pred, average='macro')  # 计算宏平均F1分数\n",
    "print(\"F1分数为: \", f1)\n",
    "# 计算Cohen's Kappa系数\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "print(\"Cohen's Kappa系数为: \", kappa)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:12:04.141262Z",
     "start_time": "2023-05-17T16:12:04.028543Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 6 模型应用\n",
    "#  读取待预测数据\n",
    "result = pd.read_csv(predict_name)\n",
    "# 预测\n",
    "y_pred = model.predict(result[columns])\n",
    "y_pred = xgb_le.inverse_transform(y_pred)\n",
    "# 保存预测结果至 star_test_lr.csv 文件\n",
    "result['credit_level'] = y_pred\n",
    "result = result.loc[:, ['uid', 'credit_level']]\n",
    "result.to_csv(PREFIX + 'result.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
